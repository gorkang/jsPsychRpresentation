---
title: "JsPsychR"
subtitle: "Open source, standard tooling for experimental protocols: towards Registered reports"
author: "**Gorka Navarrete & Herman Valencia**"
embed-resources: true
slide-number: c
output-file: "index.html"
format: 
  revealjs:
    theme: 
      - default
      - custom.scss
editor: source
echo: true
eval: false
code-fold: false
code-summary: "show code"
css: hscroll.css
bibliography: bibliography.bib

---

```{r setup}

```

# The past
_Gather 'round little ones_


## Old school science

::: {layout="[-10, 10]" layout-valign="bottom"}

![](img/shiny-logo.png){width=100% fig-align="right"}
:::


## Old school science

<BR> 

1) Read literature & come up with a _shiny_ idea
2) Design and run experiment
3) Prepare data & **explore different analytic approaches**
4) If significant result &#8594; Write paper


## Scientific method

::: {layout="[10]" layout-valign="bottom"}
![[Source: Center for Open Science |MODIFIED|](https://www.cos.io/initiatives/registered-reports)](img/issues-scientific-method-osf_clean.png){width=80% fig-align="center" text-align="center" layout-valign="bottom"}
:::


## Some issues

::: {layout="[10]" layout-valign="bottom"}
![[Source: Center for Open Science](https://www.cos.io/initiatives/registered-reports)](img/issues-scientific-method-osf.png){width=80% fig-align="center" text-align="center" layout-valign="bottom"}
:::

## Experimenter degrees of freedom, incentives, issues

- The need for significance and novelty

- Garden of forking paths [@rubin2017evaluation]

- p-hacking [@bruns2016p]

- Hypothesizing after the results are known (i.e. HARKing) [@kerr1998harking]

- False-positive research [@forstmeier2017detecting]

- Salami slicing [@rogers1999salami]


## Context

Mean number of publications for new hires in the Canadian cognitive psychology job market

::: {layout="[10]" layout-valign="bottom"}
![@pennycook2018analysis](img/job-market.png){width=80% fig-align="center" text-align="center"}
:::


## Psychology Replication crisis

:::: {.columns}

::: {.column width="55%"}

- Replication of 100 studies 
- Replication effects were half the magnitude of original effects 
- __p < 0.05__: 
  + **97%** of original studies
  + **36%** of replications

:::

::: {.column width="45%"}

![@open2015estimating](img/replication-crisis.png){}

:::

::::


## Is there a crisis? Why?

:::: {.columns}

::: {.column width="40%"}

![@baker2016reproducibility](img/reproducibility-crisis.jpeg)

:::

::: {.column width="60%"}


![](img/reproducibility-crisis2.jpeg){width=65%}
:::

::::


## {background-image="img/help-run.gif"}


# ~~Issues~~ Opportunities


## Improving Replicability


- **Improve methods**: increase n, better measures and manipulations, improve design, piloting

- **Reduce temptations**: p-hacking, hypothesizing after the results are known (i.e. HARKing), selective reporting &#8594; preregistration, internal replications

- **Openness**: transparency of the research process, sharing methods, materials, procedures, and data

@nosek2022replicability


## Registered reports (RRs) {background-image="img/unicorn.png" background-size="30%" background-position="bottom right"}

<BR><BR>
_RRs were conceived to alter the incentives for authors and journals away from producing novel, positive, clean findings and towards conducting and publishing rigorous research on important questions._ @soderberg2021initial


## RRs do help {.smaller background-image="img/RRs.png" background-size="40%" background-position="right"}

:::: {.columns}


::: {.column width="60%"}


RRs **outperformed comparison papers on all 19 criteria** [@soderberg2021initial]

Sizable improvements in:

- rigor of methodology and analysis, and overall paper quality 

Statistically indistinguishable in:

- novelty and creativity

_RRs could improve research quality while reducing publication bias..._

:::

::: {.column width="40%"}

:::

::::


## How RRs work {background-image="img/RRs.webp" background-size="40%" background-position="bottom"}

- Write introduction, method, ... before collecting data!
- Send to journal for review
- Revise and resubmit (improve before collecting data)
- Once you get _In principle acceptance_:
  + collect data & run planned analysis
  + report results and conclusions & send for final review


## RRs advantages

- More open, preregistered, reproducible by default  

- It does not matter if p value is < 0.05   

- Less incentives for p-hacking

- No hypothesizing after the results are known (HARKing)

- More trustworthy results

::: {.fragment .highlight-red}
- You still can explore, but have to say explicitly
:::



## Registered reports are great {background-image="img/sold.png" background-size="30%" background-position="center"}


## But isn't this a bit... hard?


:::: {.columns}

::: {.column width="65%"}

- It is hard to know how to analyze an experiment before having the data in front of me

- There are always surprises when receiving new data. How can I create an analysis plan that will hold?

- Collecting ALL-THE-THINGS&#8482;, allows me to figure out the best way to analyze the data afterwards

:::

::: {.column width="35%"}


![](img/upside-down.png){fig-align="right"}
:::

::::


# Our path towards RRs {background-image="img/Logo-CSCN.png" background-size="30%" background-position="bottom right"}


## Background

- In the [CSCN](https://cscn.uai.cl/) (~5-10 PI's) we used different technologies for experiments: Psychopy, Qualtrics, Limesurvey, jsPsych,...  

- Each protocol started almost from scratch. A single pre-existing task would define the technology used

- Multiple implementations of the same tasks, not always exact replicas, not always easy to find

- Some would work in certain computers, other did not

- Output data wildly different, data preparation a hard task and error prone


## Issues

<BR><BR>  

- Experiments
- Resources
- Reproducibility



## Experiment issues 

-   Errors in experiment logic
-   Errors in items coding
-   Data not what we expected
-   Data structure made data preparation hard
-   Match between hypotheses and data not clear
-   Variables or questions not used in the analysis/paper


## Resources issues: projects as islands

- Hours, days, weeks, wasted re-programming tasks
- Thousands of € 'invested' in licenses (e.g. Qualtrics)
- Piloting protocols as a part-time job for Research Assistants
- Hours, days, weeks, wasted re-doing data preparation (each software has its own output format) 


## Reproducibility issues

- Anyone knows why this 2012 paradigm/data analysis is not running?
- Location and organization of projects 
- Data preparation/analyses so ugly, sharing them is hard (let me clean up this a bit before sharing it with you)
- Idiosyncratic analyses, some of which require licensed closed software (SPSS, Matlab,...)



## Issues Survey

:::: {.columns}

::: {.column width="30%"}

:::

::: {.column width="70%"}

2 questions voluntary survey:  

![[https://cscn.uai.cl/lab/protocols/38/](https://cscn.uai.cl/lab/protocols/38/){target="_blank"}](img/QR-code.png){width=300, height=300, fig-align="left"}

:::

::::

## Our wish list

![](img/euphoria.png){width=40% fig-align="center"}

## Our wish list {background-color="white" background-image="img/magic.png" background-size="40%" background-position="bottom right"}

- Open source software based on standard technologies
- Reusable tasks (my project feeds future projects)
- Based on a mature project or technologies
- As many 'automagic' things as possible
- Easy to create and analyze paradigms
- Balancing participants
- Online/offline



# The present

A few years latter...


## jsPsychR

:::: {.columns}

::: {.column width="60%"}

Open source tools to help create experimental paradigms with [jsPsych](https://www.jspsych.org), simulate participants and standardize the data preparation and analysis  
<BR>

1\) [jsPsychMaker](https://github.com/gorkang/jsPsychMaker)

2\) [jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys)

3\) [jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR)

:::

::: {.column width="40%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## Goal

A big catalog of tasks in [jsPsychMaker](https://github.com/gorkang/jsPsychMaker). Each task runs with [jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys) to create virtual participants, and have a script in [jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR) to automate data preparation (re-coding, reversing items, calculating dimensions, etc.).
<BR><BR>

The final goal is to help you have the data preparation and analysis ready before collecting any real data, reducing errors in the protocols, and making the move towards registered reports easier.


## So far {.smaller}

- 3 main R packages (jsPsychMakeR, jsPsychMonkeys, jsPsychHelpeR)
- 1 R package for Administration tasks (jsPsychAdmin)  
- \> 80 pages [manual](https://gorkang.github.io/jsPsychRmanual/)  
- ~100 tasks ready (with maker and helper scripts, plus original paper for most)  
- \> 30 online protocols with \> 5000 participants (Prolific Academic, Social Media, etc.)  
- A number of offline (lab) protocols and participants  
- Used by researchers in Chile, Colombia, Spain  
- Everything is open source: [https://github.com/gorkang/jsPsychRmanual](https://github.com/gorkang/jsPsychRmanual)
- 2 publications using the system (50% Registered reports) + more in the pipeline...  
- **So many errors** caught early... ( ͡ᵔ ͜ʖ ͡ᵔ )


## The team

Current developers: 

- Gorka Navarrete, Herman Valencia

Initial idea and development: 

- Gorka Navarrete, Nicolas Sanchez-Fuenzalida, Nicolas Alarcón, Alejandro Cofre, Herman Valencia

Discussions, ideas, testing: 

- Esteban Hurtado, Alvaro Rivera, Juan Pablo Morales, ...


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) **[jsPsychMaker](https://github.com/gorkang/jsPsychMaker)**

2\) <span style="color:grey;">jsPsychMonkeys</span>

3\) <span style="color:grey;">jsPsychHelpeR</span>

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## jsPsychMaker

![](img/jsPsychMaker.png)

## Features jsPsychMaker {.hscroll .scrollable .smaller}

- Fully open source, based on web standards ([jsPsych](https://www.jspsych.org/))
- Reuse ~ 100 tasks
- Online and offline protocols
- Balancing of participants to between participants conditions
- Easy to create new tasks 
- Full control over order or tasks (randomization, etc.)
- Participants can continue where they left (or not)
- Time and number of participants limits
- Multilingual support (for a selected number of tasks)
- All the parameters can be quickly changed editing a single file


## Available tasks {.hscroll .scrollable .smaller}

```{r}
#| eval: true
#| echo: false
#| code-fold: false

DF_raw = readr::read_csv(here::here("Presentation/data/DF_tasks.csv"))

DT::datatable(DF_raw, filter = 'top', options = list(pageLength = 100, dom = 't'), rownames = FALSE) |>
    DT::formatStyle(columns = c(1, 2, 3), fontSize = '75%')

```

## Create New Tasks

Creating new tasks is as simple as: 

1) Copy example tasks to your computer

```{r}

jsPsychMaker::copy_example_tasks(
  destination_folder = "~/Downloads/ExampleTasks"
  )

```

2) Copy paste items, adapt csv/excel file

3) Create protocol (see next slide)





## Create protocol

Create a protocol with three existing tasks plus the adapted Example tasks:

```{r}
jsPsychMaker::create_protocol(
  canonical_tasks = c("AIM", "EAR", "IRI"),
  folder_tasks = "~/Downloads/ExampleTasks/",
  folder_output = "~/Downloads/protocol999",
  launch_browser = FALSE
)
```


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) <span style="color:grey;">jsPsychMaker</span>

2\) **[jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys)**

3\) <span style="color:grey;">jsPsychHelpeR</span>

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## jsPsychMonkeys

::: {layout="[20,-2,5]" layout-valign="bottom"}

![](img/jsMonkeys_parallel.gif)

![](img/jsPsychMonkeys.png){fig-align="center" layout-valign="bottom"}


::::



## Features jsPsychMonkeys

- Fully open source (R, docker, selenium)
- Online and offline
- Sequentially and in parallel
- Get pictures of each screen
- Store logs to make debugging easier
- Watch the monkeys as they work for you
- Random pauses or refreshing to simulate human behavior
- Set random seed to make the monkey's behavior consistent


## Release monkeys

Release a single Monkey and take a look:

```{r}

jsPsychMonkeys::release_the_monkeys(
  uid = 11,
  initial_wait = 0,
  wait_retry = 0,
  local_folder_tasks = "~/Downloads/protocol999/",
  open_VNC = TRUE
)
```

Release 10 Monkeys in parallel:

```{r}
jsPsychMonkeys::release_the_monkeys(
  uid = 1:10,
  sequential_parallel = "parallel",
  number_of_cores = 10,
  local_folder_tasks = "~/Downloads/protocol999/",
  open_VNC = FALSE
)
```


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) <span style="color:grey;">jsPsychMaker</span>

2\) <span style="color:grey;">jsPsychMonkeys</span>

3\) **[jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR)**

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::




## jsPsychHelpeR

![](img/jsPsychHelpeR.png)


## Features jsPsychHelpeR {.hscroll .scrollable .smaller}

- Fully open source (R)
- Get tidy output data frames for each task, and for the whole protocol
- Standard naming for tasks, dimensions, scales, ...
- Include tests for common issues
- Snapshots to detect changes in data processing
- Functions to help create new tasks correction using a standard template
- Automatic reports with progress, descriptive statistics, code-book, etc.
- Create a fully reproducible Docker container with the project's data preparation and analysis
- Create a blinded data frame to perform blinded analyses



## jsPsychHelpeR

Create project for data preparation:

```{r}
jsPsychHelpeR::run_initial_setup(
  pid = 999,
  data_location = "~/Downloads/protocol999/.data/",
  folder = "~/Downloads/jsPsychR999"
  )
```

Create a task correction script:  

```{r}
jsPsychHelpeR::create_new_task("MultiChoice")
```

Visualize and run data preparation:  

```{r}
targets::tar_visnetwork(targets_only = TRUE, label = "time")

targets::tar_make()
```


## Challenge: everything in 3 minutes?

Create protocol, simulate participants and prepare data...

```{r, eval=FALSE}

# Full process
rstudioapi::navigateToFile("R/script-full-process.R")

```

[Create, simulate, prepare](https://www.youtube.com/watch?v=2OXI9lzE3zU){target="_blank"}

{{< video https://www.youtube.com/watch?v=2OXI9lzE3zU width="600" height="400" >}}


## Survey Experiment Issues 

![](img/survey-issues.png){width=50% fig-align="center"}

## Survey results

Let's try to download the data, process it and show a report with the results:  

<BR>
Plan A: run Experiment Issues project

```{r, eval=FALSE}

rstudioapi::openProject("../jsPsychHelpeR-ExperimentIssues/jsPsychHelpeR-ExperimentIssues.Rproj", newSession = TRUE)

```

<BR><BR>
Plan B: If something fails, we always have the monkeys!

```{r, eval=FALSE}

browseURL("../jsPsychHelpeR-ExperimentIssues/outputs/reports/report_analysis_monkeys.html")

```

## {-}

![](img/perfect.png){fig-align="center"}

## Limitations

- Very easy to create new scales, and simple tasks, but complex experimental tasks <span style="color:orange;">require javascript and HTML knowledge</span> (although there are a good number of examples available)

- Data preparation for <span style="color:grey;">new experimental tasks</span> requires expertise in R (simple surveys not so much)  

- Analysis reports require some R knowledge (simple templates available)

- Requires access to a server for online tasks  

- Only behavioral tasks


# The future

 _The past is always tense, the future perfect._ Zadie Smith

## {background-color="black" background-image="img/future.jpg"}

## Too many things, too little time {background-image="img/working.gif"  background-size="20%" background-position="bottom right"}

- Create templates for most common experimental designs  
- Templates for data preparation and analysis of common experimental designs  
- More tasks, translations, tests, ...  
- So far, development based in our needs (and possibilities)  
- Upgrade to latest jsPsych when available  
- Improve, clean, share...  
- Publish jsPsychR paper  


## Help {background-image="img/help.png" background-size="20%" background-position="bottom right"}

- Javascript programmers

- R programmers

- Task creators

- Testers


## Back to Registered reports

<BR><BR><BR>
![](img/RRs.webp)

## Can jsPsych really help? (1/2)

- With jsPsychR, protocols are standardized with (mostly) clean code, open source, and based on web standards 

- Data preparation is 90% automatic, standardized, and beautiful 

- Less errors in protocols and in data preparation

- Time from idea to protocol much lower

- When errors are found and fixed, **old protocols can benefit from the corrections**, old results can be checked, ...


## Can jsPsych really help? (2/2)

- Trivial to work on analysis <span style="color:darkgreen;">before</span> collecting human data

- Much easier to write up a good analysis plan, share it, improve it, ...

- Create fully reproducible papers and results' reports easily

- Sharing protocol, materials, data preparation is trivial (single command)

- Creating future-proof fully reproducible data preparation projects (with Docker) is one command away



## jsPsychR &#9829; RRs

![](img/reproducibility-crisis2_solved.jpeg){width=65% fig-align="center"}



## Improving Peer Review

<BR>

:::: {.columns}

::: {.column width="55%"}

- Data should be made publicly available

- Stimuli and materials should be made publicly available

- The location of all of these files should be advertised in the manuscript, ...

:::

::: {.column width="45%"}

![Source: [https://www.opennessinitiative.org/](https://www.opennessinitiative.org/)](img/PRO.png){width=80% fig-align="center" text-align="center" layout-valign="bottom"}


:::

::::
## More information

For more information about RRs, templates, checklists, list of participating journals (\>300), etc.:  

- [https://www.cos.io/initiatives/registered-reports](https://www.cos.io/initiatives/registered-reports)


Also, check out the future:  

- RRs v2: [Peer community in](https://peercommunityin.org/)

And our manual:

- [https://gorkang.github.io/jsPsychRmanual/](https://gorkang.github.io/jsPsychRmanual/)

## References

::: {#refs}
:::

## Thanks!

<BR><BR>

<span style="color:grey;">Gorka Navarrete</span>

gorkang\@gmail.com  

https://fosstodon.org/\@gorkang  


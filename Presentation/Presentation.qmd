---
title: "JsPsychR"
subtitle: "Open source, standard tooling for experimental protocols: towards Registered reports"
author: "**Gorka Navarrete & Herman Valencia**"
embed-resources: true
slide-number: c
output-file: "index.html"
format: 
  revealjs:
    theme: 
      - default
      - custom.scss
editor: source
echo: true
eval: false
code-fold: false
code-summary: "show code"
css: custom.css
bibliography: bibliography.bib

---

```{r setup}

```

# The past
_Gather 'round little ones_


## Old school science

::: {layout="[-10, 10]" layout-valign="bottom"}

![](img/shiny-logo.png){width=100% fig-align="right"}
:::


## Old school science

<BR> 

1) Read literature & come up with a _shiny_^[Novel, counter-intuitive, interesting,...] idea
2) Design and run experiment
3) Prepare data & **explore different analytic approaches**
4) If significant result &#8594; Write paper


## Scientific method

::: {layout="[10]" layout-valign="bottom"}
![[Source: Center for Open Science |MODIFIED|](https://www.cos.io/initiatives/registered-reports)](img/issues-scientific-method-osf_clean.png){width=80% fig-align="center" text-align="center" layout-valign="bottom"}
:::


## Some issues

::: {layout="[10]" layout-valign="bottom"}
![[Source: Center for Open Science](https://www.cos.io/initiatives/registered-reports)](img/issues-scientific-method-osf.png){width=80% fig-align="center" text-align="center" layout-valign="bottom"}
:::

## Experimenter degrees of freedom, incentives, issues

The need for significance and novelty:  

- Garden of forking paths [@rubin2017evaluation]

- p-hacking [@bruns2016p]

- Hypothesizing after the results are known (i.e. HARKing) [@kerr1998harking]

- False-positive research [@forstmeier2017detecting]

- Salami slicing [@rogers1999salami]


## Psychology Replication crisis

Replication of 100 studies ^[From Psychological Science (PSCI), Journal of Personality and Social Psychology (JPSP), and Journal of Experimental Psychology: Learning, Memory, and Cognition (JEP: LMC)]

:::: {.columns}

::: {.column width="60%"}


**Statistically significant**:  

-  **97%** original &#8594; **36%** replications

**Effect sizes**:

- Replication effects were half the magnitude of original effects 


:::

::: {.column width="40%"}

![@open2015estimating](img/replication-crisis.png)

:::

::::


## Is there a crisis?

![@baker2016reproducibility](img/reproducibility-crisis.jpeg)


## Contributing factors


![@baker2016reproducibility](img/reproducibility-crisis2.jpeg){width=65%}


## Context

Mean number of publications for new hires in the Canadian cognitive psychology job market

::: {layout="[10]" layout-valign="bottom"}
![@pennycook2018analysis](img/job-market.png){width=80% fig-align="center" text-align="center"}
:::



## And not only Psychology


- Medicine [@ioannidis2005most]

- Cancer research [@begley2012raise]

- Finance [@bettis2012search]

- Economics [@maniadis2017replicate]

- Health informatics [@coiera2018does]

- Operations and supply chain management [@pagell2021replication]

- Methodological research [@boulesteix2020replication]

- Education [@frias2020replication]

- ...



## {background-image="img/help-run.gif"}


# Issues

# ~~Issues~~ Opportunities


## Improving Replicability

<BR>  

**Improve methods**

**Reduce errors**

**Openness**

<BR>  
@nosek2022replicability


## Improving Replicability

<BR> 

**Improve methods**

  + increase number of participants
  + better measures and manipulations
  + improve design
  + piloting


## Improving Replicability

<BR> 

**Reduce errors**

- preregistration:  

  + p-hacking
  + hypothesizing after the results are known (i.e. HARKing)
  + selective reporting

- internal replications



## Improving Replicability

<BR> 

**Openness**

- transparency of the research process  

- sharing methods, materials, procedures, and data


# Registered reports {background-image="img/unicorn.png" background-size="40%" background-position="bottom right"}

## Registered reports (RRs) {background-image="img/unicorn.png" background-size="20%" background-position="bottom right"}

<BR><BR>
_RRs were conceived to alter the incentives for authors and journals away from producing novel, positive, clean findings and towards conducting and publishing rigorous research on important questions._ @soderberg2021initial


## RRs do help {.smaller background-image="img/RRs.png" background-size="40%" background-position="right"}

:::: {.columns}


::: {.column width="60%"}


RRs **outperformed comparison papers on all 19 criteria** [@soderberg2021initial]

<BR> 

Sizable improvements in:

- rigor of methodology and analysis, and overall paper quality 

Statistically indistinguishable in:

- novelty and creativity

_RRs could improve research quality while reducing publication bias..._

:::

::: {.column width="40%"}

:::

::::


## How RRs work {background-image="img/RRs.webp" background-size="40%" background-position="bottom"}

- Write introduction, method, ... before collecting data!
- Send to journal for review
- Revise and resubmit (improve before collecting data)
- Once you get _In principle acceptance_:
  + collect data & run planned analysis
  + report results and conclusions & send for final review


## RRs advantages

- More open, preregistered, reproducible by default  

- It does not matter if p value is < 0.05   

- Less incentives for p-hacking

- No hypothesizing after the results are known (HARKing)

- More trustworthy results

::: {.fragment .highlight-red}
- You still can explore, but have to say explicitly
:::



## Registered reports are great {background-image="img/sold.png" background-size="30%" background-position="center"}


## But isn't this a bit... hard?


:::: {.columns}

::: {.column width="70%"}

- Hard to know how to analyze an experiment before having the data

- Always surprises when data arrives. How to create an analysis plan that will hold?

- Collecting ALL-THE-THINGS&#8482; allows me to figure out the best way to do analysis

:::

::: {.column width="30%"}


![](img/upside-down.png){fig-align="right"}
:::

::::


# Our path towards RRs {background-image="img/Logo-CSCN.png" background-size="30%" background-position="bottom right"}


## Background

- At the [CSCN](https://cscn.uai.cl/) (~5-10 PI's) we used different technologies for experiments: Psychopy, Qualtrics, Limesurvey, jsPsych,...  

- Each protocol started almost from scratch. A single pre-existing task would define the technology used

- Multiple implementations of the same tasks, not always exact replicas, not always easy to find

- Some would work in certain computers, other did not

- Output data wildly different, data preparation a hard task and error prone


## Issues

<BR><BR>  

- Experiments
- Resources
- Reproducibility



## Experiment issues 

-   Errors in experiment logic
-   Errors in items coding
-   Data not what we expected
-   Data structure made data preparation hard
-   Match between hypotheses and data not clear
-   Variables or questions not used in the analysis/paper


## Resources issues: projects as islands

- Time wasted re-programming tasks
- Thousands of $/â‚¬ 'invested' in licenses (e.g. Qualtrics)
- Piloting protocols as a part-time job for Research Assistants
- Time wasted re-doing data preparation (each software has its own output format) 


## Reproducibility issues

- Can I see what the participants saw in the 2012 protocol?
- Data preparation/analyses so ugly, sharing them is hard (let me clean up this a bit before sending it)
- Idiosyncratic analyses, some of which require licensed closed software (SPSS, Matlab,...)
- Location and organization of projects 
- Why is this 2012 paradigm/data analysis is not running?



## Issues Survey

:::: {.columns}

::: {.column width="30%"}

:::

::: {.column width="70%"}

2 questions survey:  

![[https://cscn.uai.cl/lab/protocols/38/](https://cscn.uai.cl/lab/protocols/38/){target="_blank"}](img/QR-survey.svg){width=400, fig-align="left"}

:::

::::

## Our wish list {background-image="img/euphoria.png" background-size="15%"}


## Our wish list {background-image="img/magic.png" background-size="30%" background-position="bottom right"}

- Open source software based on standard technologies
- Reusable tasks (my project feeds future projects)
- Based on a mature project or technologies [@de2015jspsych] ^[Psych: [https://www.jspsych.org/](https://www.jspsych.org/)]
- As many 'automagic' things as possible
- Easy to create and analyze paradigms
- Balancing participants
- Online/offline
- etc.



# The present

A few years latter...


## jsPsychR

:::: {.columns}

::: {.column width="60%"}

Open source tools to help create experimental paradigms with [jsPsych](https://www.jspsych.org), simulate participants and standardize the data preparation and analysis  
<BR>

1\) [jsPsychMaker](https://github.com/gorkang/jsPsychMaker)

2\) [jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys)

3\) [jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR)

:::

::: {.column width="40%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## The tool

<BR>

A big catalog of tasks in [jsPsychMaker](https://github.com/gorkang/jsPsychMaker). Each task runs with [jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys) to create virtual participants, and have a script in [jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR) to automate data preparation (re-coding, reversing items, calculating dimensions, etc.)


## The goal

<BR>

The final goal is to help you **have the data preparation and analysis ready before collecting any real data**, reducing errors in the protocols, and making the move towards registered reports easier


## So far

- ~100 tasks (maker + helper)  
- Used by researchers in Chile, Colombia, Spain: 
  + \> 30 online protocols with \> 5000 participants (Prolific Academic, Social Media, etc.)  + offline
- Everything open source. \> 80 pages [manual](https://gorkang.github.io/jsPsychRmanual/)
- &#9829; **So, many, errors,** caught early &#9829;  

<!-- - 2 publications using the system (50% Registered reports) + more in the pipeline...   -->
 <!-- {.smaller} -->

## The team

Gorka Navarrete, Herman Valencia

<BR>

Initial idea and development: 

- Gorka Navarrete, Nicolas Sanchez-Fuenzalida, Nicolas AlarcÃ³n, Alejandro Cofre, Herman Valencia

Discussions, ideas, testing: 

- Esteban Hurtado, Alvaro Rivera, Juan Pablo Morales, ...


## jsPsychR

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) **[jsPsychMaker](https://github.com/gorkang/jsPsychMaker)**

2\) <span style="color:grey;">jsPsychMonkeys</span>

3\) <span style="color:grey;">jsPsychHelpeR</span>

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## jsPsychMaker

![](img/jsPsychMaker.png)

## Features jsPsychMaker {.hscroll .scrollable .smaller}

- Fully open source, based on web standards ([jsPsych](https://www.jspsych.org/))
- Reuse ~ 100 tasks
- Online and offline protocols
- Balancing of participants to between participants conditions
- Easy to create new tasks 
- Full control over order or tasks (randomization, etc.)
- Participants can continue where they left (or not)
- Time and number of participants limits
- Multilingual support (for a selected number of tasks)
- All the parameters can be quickly changed editing a single file


## Available tasks {.hscroll .scrollable .smaller}

```{r}
#| eval: true
#| echo: false
#| code-fold: false

DF_raw = readr::read_csv(here::here("Presentation/data/DF_tasks.csv"))

DT::datatable(DF_raw, filter = 'top', options = list(pageLength = 100, dom = 't'), rownames = FALSE) |>
    DT::formatStyle(columns = c(1, 2, 3), fontSize = '75%')

```

## Create New Tasks

Creating new tasks is as simple as: 

1) Copy example tasks to your computer

```{r}

jsPsychMaker::copy_example_tasks(
  destination_folder = "~/Downloads/ExampleTasks", 
  which_tasks = "Slider"
  )

```

2) Copy paste items, adapt csv/excel file

```{r}
system("nautilus ~/Downloads/ExampleTasks/Slider/Slider.csv")
```


3) Create protocol (see next slide)





## Create protocol

<BR>
Create a protocol with: 

- 3 existing tasks: AIM, BNT, CRT
- the adapted Example tasks (Slider)


```{r}
jsPsychMaker::create_protocol(
  canonical_tasks = c("AIM", "BNT", "CRTMCQ4"),
  folder_tasks = "~/Downloads/ExampleTasks/",
  folder_output = "~/Downloads/protocol9996",
  launch_browser = TRUE
)
```


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) <span style="color:grey;">jsPsychMaker</span>

2\) **[jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys)**

3\) <span style="color:grey;">jsPsychHelpeR</span>

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## jsPsychMonkeys

::: {layout="[20,-2,5]" layout-valign="bottom"}

![](img/jsMonkeys_parallel.gif)

![](img/jsPsychMonkeys.png){fig-align="center" layout-valign="bottom"}


::::



## Features jsPsychMonkeys

- Fully open source (R, docker, selenium)
- Works for online and offline protocols
- Sequentially and in parallel
- Get pictures of each screen
- Store logs to make debugging easier
- Watch the monkeys as they work for you
- Random pauses or refreshing to simulate human behavior
- Set random seed to make the monkey's behavior predictable


## Release monkeys

Release a single Monkey and take a look:

```{r}
jsPsychMonkeys::release_the_monkeys(
  uid = 11,
  local_folder_tasks = "~/Downloads/protocol9996/",
  open_VNC = TRUE,
  wait_retry = 0
)
```

<BR>
Release 10 Monkeys in parallel:

```{r}
jsPsychMonkeys::release_the_monkeys(
  uid = 1:10,
  sequential_parallel = "parallel",
  number_of_cores = 10,
  local_folder_tasks = "~/Downloads/protocol9996/",
  open_VNC = FALSE
)
```


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) <span style="color:grey;">jsPsychMaker</span>

2\) <span style="color:grey;">jsPsychMonkeys</span>

3\) **[jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR)**

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::




## jsPsychHelpeR

![](img/jsPsychHelpeR.png)


## Features jsPsychHelpeR {.hscroll .scrollable .smaller}

- Fully open source (R) 
- Get tidy output data frames for each task, and for the whole protocol
- Standard naming for tasks, dimensions, scales, ...
- Include tests for common issues
- Snapshots to detect changes in data processing
- Functions to help create new tasks correction using a standard template
- Automatic reports with progress, descriptive statistics, code-book, etc.
- Create a fully reproducible Docker container with the project's data preparation and analysis
- Create a blinded data frame to perform blinded analyses



## jsPsychHelpeR

<BR>
Create project for data preparation:

```{r}
jsPsychHelpeR::run_initial_setup(
  pid = 9996,
  data_location = "~/Downloads/protocol9996/.data/",
  folder = "~/Downloads/jsPsychHelpeR9996", 
  dont_ask = TRUE
  )
```


## Challenge: everything in 3 minutes?

Create protocol, simulate participants and prepare data...

```{r, eval=FALSE}
rstudioapi::navigateToFile("R/script-full-process.R")
```

[Create, simulate, prepare](https://www.youtube.com/watch?v=2OXI9lzE3zU){target="_blank"}

{{< video https://www.youtube.com/watch?v=2OXI9lzE3zU width="600" height="400" >}}


## Survey Experiment Issues 

![](img/survey-issues.png){width=50% fig-align="center"}

## Survey results

Let's try to download the data, process it and show a report with the results:  

<BR>
Plan A: run Experiment Issues project

```{r}

rstudioapi::openProject("jsPsychHelpeR-ExperimentIssues/jsPsychHelpeR-ExperimentIssues.Rproj", newSession = TRUE)

```

<BR><BR>
Plan B: If something fails, we always have the monkeys!

```{r}

utils::browseURL(here::here("jsPsychHelpeR-ExperimentIssues/outputs/reports/report_analysis_monkeys.html"), 
                 browser = "firefox")

```

## {-}

![](img/perfect.png){fig-align="center"}

## Limitations

- Easy to create new scales and simple tasks, but complex experimental tasks <span style="color:red;">require javascript knowledge</span> (although there are a good number of examples available)

- Data preparation for new experimental tasks <span style="color:red;">requires expertise in R</span> (simple surveys not so much)  

- Analysis reports require some R knowledge (simple templates available)

- Needs access to a server for online tasks  

- Only behavioral tasks


# The future

 _The past is always tense, the future perfect_  

<span style="color:grey;">Zadie Smith</span> 


## {background-color="black" background-image="img/future.jpg"}

## Too many things, too little time {background-image="img/working.gif"  background-size="20%" background-position="bottom right"}

Development is linked to our needs, time and resources. Future roadmap:  

- Templates for common experimental designs (tasks, data preparation and analysis)  
- More tasks, translations, tests, ...  
- Upgrade, improve, clean, share
- jsPsychR paper  


## Help wellcome! {background-image="img/help.png" background-size="20%" background-position="bottom right"}

- Javascript programmers

- R programmers

- Documentation

- Task creators

- Testers

- Coffee brewers

- Patrons


## Back to Registered reports

<BR><BR><BR>
![](img/RRs.webp)

## Can jsPsychR really help? (1/2)

- Protocols are standardized with (mostly) clean code, open source, and based on web standards 

- Data preparation 90% automatic, standardized, beautiful 

- **Less errors** in protocols and in data preparation

- Time from idea to protocol much lower

- When errors are found and fixed, **old protocols can benefit from the corrections**, old results can be checked, ...


## Can jsPsychR really help? (2/2)

- Trivial to work on analysis **before collecting human data**

- Much easier to write up a good analysis plan, share it, improve it, ...

- Easy to create **fully reproducible** papers and results' reports

- Sharing protocol, materials, data preparation is painless (single command) ^[`usethis::use_github()`]

- Creating future-proof fully reproducible data preparation projects (with Docker) is one command away ^[`jsPsychHelpeR::create_docker_container()`]



## jsPsychR &#9829; Registered Reports

![](img/reproducibility-crisis2_solved.jpeg){width=65% fig-align="center"}

## More information

RRs' templates, checklists, participating journals (\> 300):  

- [https://www.cos.io/initiatives/registered-reports](www.cos.io/initiatives/registered-reports)


Also, check out the future:  

- RRs v2: [Peer community in](https://peercommunityin.org/)

And if you are a reviewer:

- No reviews unless data, stimuli and materials are publicly available ([www.opennessinitiative.org/](www.opennessinitiative.org/))


## References

::: {#refs}
:::


# Thanks!

<span style="color:grey;">Gorka Navarrete</span>

gorkang\@gmail.com  

::: {layout="[-30, 10]" layout-valign="bottom"}

![](img/QR-presentation.svg){width=70% fig-align="right"}

:::

::: footer

Presentation: [https://gorkang.github.io/jsPsychRpresentation/](https://gorkang.github.io/jsPsychRpresentation/)  
Manual: [https://gorkang.github.io/jsPsychRmanual/](https://gorkang.github.io/jsPsychRmanual/)  
Contact: [https://fosstodon.org/\@gorkang](https://fosstodon.org/\@gorkang)
:::

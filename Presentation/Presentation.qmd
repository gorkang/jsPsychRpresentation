---
title: "JsPsychR"
subtitle: "Open source, standard tooling for experimental protocols: towards Registered reports"
author: "**Gorka Navarrete & Herman Valencia**"
embed-resources: true
output-file: "index.html"
format: revealjs
editor: source
echo: true
eval: false
code-fold: false
code-summary: "show code"
css: hscroll.css
bibliography: bibliography.bib
---

```{r setup}

```

# The past  

## Running experiments

<BR>
Old school:  

1) Read a bit & come up with an idea
2) Prepare and run experiment
3) Prepare data & explore different analytic approaches
4) Significant result &#8594; Write paper


## Some issues {background-image="img/issues-scientific-method-osf.png" background-size="60%" background-position="bottom" .smaller}

[https://www.cos.io/initiatives/registered-reports](https://www.cos.io/initiatives/registered-reports)

## Experimenter degrees of freedom, incentives, issues

- What if... &#8594; Garden of forking paths [@rubin2017evaluation]

- p-hacking, hypothesizing after the results are known (i.e. HARKing)

- The need for significance and novelty

- False positives research 


## Psychology Replication crisis


:::: {.columns}


::: {.column width="55%"}

- Replication of 100 studies 
- Replication effects were half the magnitude of original effects 
- __p < 0.05__: 
  + **97%** of original studies
  + **36%** of replications

@open2015estimating
:::

::: {.column width="45%"}


![](img/replication-crisis.png)
:::

::::


## Is there a crisis? Why?

:::: {.columns}

::: {.column width="40%"}

![](img/reproducibility-crisis.jpeg)
@baker2016reproducibility

:::

::: {.column width="60%"}


![](img/reproducibility-crisis2.jpeg){width=65%}
:::

::::


##  {background-image="img/help-run.gif"}



## Improving Replicability

- **Improve methods**: increase n, better measures and manipulations, improve design, piloting

- **Reduce temptations**: p-hacking, hypothesizing after the results are known (i.e. HARKing), selective reporting &#8594; preregistration, internal replications

- **Openness**: transparency of the research process, sharing methods, materials, procedures, and data

@nosek2022replicability


## Registered reports (RR) {background-image="img/unicorn.png" background-size="30%" background-position="bottom right"}

<BR><BR>
_RRs were conceived to alter the incentives for authors and journals away from producing novel, positive, clean findings and towards conducting and publishing rigorous research on important questions._ @soderberg2021initial


## RR do help {background-image="img/RR.png" background-size="40%" background-position="bottom right"}


## How RR work {background-image="img/RR.webp" background-size="50%" background-position="bottom"}

- Write introduction, method, ... before collecting data!
- Send to journal for review
- Revise and resubmit (improve before collecting data)
- Once you get _In principle acceptance_, collect human data, run analysis, write up, and send for a final review


## RR advantages

- More open, preregistered, reproducible by default  

- It does not matter if p value is < 0.05   

- Less incentives for p-hacking  

- More trustworthy results  

::: {.fragment .highlight-red}
- You still can explore, but have to say explicitly
:::



## Registered reports are great {background-image="img/sold.png" background-size="30%" background-position="center"}


## But isn't this a bit...


<BR><BR>

:::: {.columns}


::: {.column width="60%"}

- Before having the data available, it is hard to know how to analyze it

- There are always surprises when receiving new data. How can I create an analysis plan that will hold?

:::

::: {.column width="40%"}


![](img/upside-down.png){width=300, height=300, fig-align="right"}
:::

::::


## Our path towards RR


<BR><BR>

:::: {.columns}


::: {.column width="30%"}

:::

::: {.column width="70%"}


![](img/Logo-CSCN.png){width=500}
:::

::::



## Background

We ([CSCN](https://cscn.uai.cl/); ~5-10 PI's) used different technologies to develop experiments: Psychopy, Qualtrics, Limesurvey, jsPsych, etc.  
<BR>

Each of these has <span style="color:darkgreen;">advantages</span> and <span style="color:orange;">disadvantages.</span>  <BR><BR>

Mostly, pragmatic aspects guided the decision: lab history and resources, coding experience, type of experiment (EEG/behavioral, lab/online), ...


## Issues {background-image="img/this-is-fine.jpg" background-size="30%" background-position="bottom right"}

Each protocol started almost from scratch. Sometimes a single task would define the technology used.<BR><BR>

At some point, we had multiple implementations of the same tasks in different technologies, not always exact replicas.<BR><BR>

Some would work in certain computers, other did not. Output data wildly different.<BR><BR>


## Issues Survey

:::: {.columns}

::: {.column width="30%"}

<BR><BR>  

- Experiments
- Resources
- Reproducibility

:::

::: {.column width="70%"}

2 questions voluntary survey:  

![[https://cscn.uai.cl/lab/protocols/38/](https://cscn.uai.cl/lab/protocols/38/){target="_blank"}](img/QR-code.png){width=300, height=300, fig-align="left"}

:::

::::


## Experiment issues 

-   Errors in experiment logic
-   Errors in items coding
-   Data not what we expected
-   Data structure makes data preparation hard
-   Match between hypotheses and data not clear
-   Variables or questions not used in the analysis/paper


## Resources issues: projects as islands

- Hours wasted re-programming tasks
- Thousands of € 'invested' in licenses (e.g. Qualtrics)
- Piloting protocols as a part-time job for Research Assistants
- Hours wasted re-doing data preparation (each software has its own output format) 


## Reproducibility issues

- Anyone knows why this 2012 paradigm/data analysis is not running?
- Location and organization of projects 
- Data preparation/analyses so ugly, sharing them is hard (let me clean up this a bit before sharing it with you)
- Idiosyncratic analyses, some of which require licensed closed software (SPSS, Matlab,...)


## Our wish list

![](img/euphoria.webp){width=50% fig-align="center"}

## Our wish list {background-color="white" background-image="img/magic.png" background-size="40%" background-position="bottom right"}

- Open source software based on standard technologies
- Reusable tasks (my project feeds future projects)
- Based on a mature project or technologies
- As many 'automagic' things as possible
- Easy to create and analyze paradigms
- Balancing participants
- Online/offline



# The present



## jsPsychR

:::: {.columns}

::: {.column width="60%"}

Open source tools to help create experimental paradigms with [jsPsych](https://www.jspsych.org), simulate participants and standardize the data preparation and analysis  
<BR>

1\) [jsPsychMaker](https://github.com/gorkang/jsPsychMaker)

2\) [jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys)

3\) [jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR)

:::

::: {.column width="40%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## Goal

A big catalog of tasks in [jsPsychMaker](https://github.com/gorkang/jsPsychMaker). Each task runs with [jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys) to create virtual participants, and have a script in [jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR) to automate data preparation (re-coding, reversing items, calculating dimensions, etc.).
<BR><BR>

The final goal is to help you have the data preparation and analysis ready before collecting any real data, reducing errors in the protocols, and making the move towards registered reports easier.


## So far {.smaller}

- 3 main R packages (jsPsychMakeR, jsPsychMonkeys, jsPsychHelpeR)
- 1 R package for Administration tasks (jsPsychAdmin)  
- \> 80 pages [manual](https://gorkang.github.io/jsPsychRmanual/)  
- ~100 tasks ready (with maker and helper scripts, plus original paper for most)  
- \> 30 online protocols with \> 5000 participants (Prolific Academic, Social Media, etc.)  
- A number of offline (lab) protocols and participants  
- Used by researchers in Chile, Colombia, Spain  
- Everything is open source: [https://github.com/gorkang/jsPsychRmanual](https://github.com/gorkang/jsPsychRmanual)
- 2 publications using the system (50% Registered reports) + more in the pipeline...  
- So many errors caught early... ( ͡ᵔ ͜ʖ ͡ᵔ )


## The team

Current developers: 

- Gorka Navarrete, Herman Valencia

Initial idea and development: 

- Gorka Navarrete, Nicolas Sanchez-Fuenzalida, Nicolas Alarcón, Alejandro Cofre, Herman Valencia

Discussions, ideas, testing: 

- Esteban Hurtado, Alvaro Rivera, Juan Pablo Morales, ...


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) **[jsPsychMaker](https://github.com/gorkang/jsPsychMaker)**

2\) <span style="color:grey;">jsPsychMonkeys</span>

3\) <span style="color:grey;">jsPsychHelpeR</span>

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## jsPsychMaker

![](img/jsPsychMaker.png)

## Features jsPsychMaker {.hscroll .scrollable .smaller}

- Fully open source, based on web standards ([jsPsych](https://www.jspsych.org/))
- Reuse ~ 100 tasks
- Online and offline protocols
- Balancing of participants to between participants conditions
- Easy to create new tasks 
- Full control over order or tasks (randomization, etc.)
- Participants can continue where they left (or not)
- Time and number of participants limits
- Multilingual support (for a selected number of tasks)
- All the parameters can be quickly changed editing a single file


## Available tasks {.hscroll .scrollable .smaller}

```{r}
#| eval: true
#| echo: false
#| code-fold: false

googlesheets4::gs4_auth("gorkang@gmail.com")

DF_raw = googlesheets4::read_sheet("1Eo0F4GcmqWZ1cghTpQlA4aHsc8kTABss-HAeimE2IqA", sheet = 2, skip = 0) |>
    dplyr::rename(short_name = `Codigo Test`) |>
    dplyr::filter(!grepl("short_name", short_name)) |>
    dplyr::arrange(short_name) |>
    dplyr::select(short_name, Nombre, Descripcion) |>
    tidyr::drop_na(short_name)

DF_raw_NEW = googlesheets4::read_sheet("1LAsyTZ2ZRP_xLiUBkqmawwnKWgy8OCwq4mmWrrc_rpQ", sheet = 2, skip = 0)


DT::datatable(DF_raw, filter = 'top', options = list(pageLength = 100, dom = 't'), rownames = FALSE) |>
    DT::formatStyle(columns = c(1, 2, 3), fontSize = '75%')

```

## Create New Tasks

Creating new tasks is as simple as: 

1) Copy example tasks to your computer

```{r}

jsPsychMaker::copy_example_tasks(
  destination_folder = "~/Downloads/ExampleTasks"
  )

```

2) Copy paste items, adapt csv/excel file

3) Create protocol (see next slide)





## Create protocol

Create a protocol with three existing tasks plus the adapted Example tasks:

```{r}
jsPsychMaker::create_protocol(
  canonical_tasks = c("AIM", "EAR", "IRI"),
  folder_tasks = "~/Downloads/ExampleTasks/",
  folder_output = "~/Downloads/protocol999",
  launch_browser = FALSE
)
```


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) <span style="color:grey;">jsPsychMaker</span>

2\) **[jsPsychMonkeys](https://github.com/gorkang/jsPsychMonkeys)**

3\) <span style="color:grey;">jsPsychHelpeR</span>

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::


## jsPsychMonkeys

::: {layout="[20,-2,5]" layout-valign="bottom"}

![](img/jsMonkeys_parallel.gif)

![](img/jsPsychMonkeys.png){fig-align="center" layout-valign="bottom"}


::::



## Features jsPsychMonkeys

- Fully open source (R, docker, selenium)
- Online and offline
- Sequentially and in parallel
- Get pictures of each screen
- Store logs to make debugging easier
- Watch the monkeys as they work for you
- Random pauses or refreshing to simulate human behavior
- Set random seed to make the monkey's behavior consistent


## Release monkeys

Release a single Monkey and take a look:

```{r}

jsPsychMonkeys::release_the_monkeys(
  uid = 11,
  initial_wait = 0,
  wait_retry = 0,
  local_folder_tasks = "~/Downloads/protocol999/",
  open_VNC = TRUE
)
```

Release 10 Monkeys in parallel:

```{r}
jsPsychMonkeys::release_the_monkeys(
  uid = 1:10,
  sequential_parallel = "parallel",
  number_of_cores = 10,
  local_folder_tasks = "~/Downloads/protocol999/",
  open_VNC = FALSE
)
```


## jsPsychR tools

:::: {.columns}

::: {.column width="40%"}

<BR><BR>
1\) <span style="color:grey;">jsPsychMaker</span>

2\) <span style="color:grey;">jsPsychMonkeys</span>

3\) **[jsPsychHelpeR](https://github.com/gorkang/jsPsychHelpeR)**

:::

::: {.column width="60%"}

![](img/jsPsych-trinity.png){fig-align="center"}

:::

::::




## jsPsychHelpeR

![](img/jsPsychHelpeR.png)


## Features jsPsychHelpeR {.hscroll .scrollable .smaller}

- Fully open source (R)
- Get tidy output data frames for each task, and for the whole protocol
- Standard naming for tasks, dimensions, scales, ...
- Include tests for common issues
- Snapshots to detect changes in data processing
- Functions to help create new tasks correction using a standard template
- Automatic reports with progress, descriptive statistics, code-book, etc.
- Create a fully reproducible Docker container with the project's data preparation and analysis
- Create a blinded data frame to perform blinded analyses



## jsPsychHelpeR

Create project for data preparation:

```{r}
jsPsychHelpeR::run_initial_setup(
  pid = 999,
  data_location = "~/Downloads/protocol999/.data/",
  folder = "~/Downloads/jsPsychR999"
  )
```

Create a task correction script:  

```{r}
jsPsychHelpeR::create_new_task("MultiChoice")
```

Visualize and run data preparation:  

```{r}
targets::tar_visnetwork(targets_only = TRUE, label = "time")

targets::tar_make()
```


## Challenge: everything in 3 minutes?

Create protocol, simulate participants and prepare data...

```{r, eval=FALSE}

# Full process
rstudioapi::navigateToFile("R/script-full-process.R")

```
<BR>

{{< video https://www.youtube.com/watch?v=2OXI9lzE3zU width="600" height="400" >}}


## Survey Experiment Issues {background-image="img/survey-issues.png" background-size="50%" background-position="bottom"}

## Survey results

Let's try to download the data, process it and show a report with the results:  

<BR>
Plan A: run Experiment Issues project

```{r, eval=FALSE}

rstudioapi::openProject("../jsPsychHelpeR-ExperimentIssues/jsPsychHelpeR-ExperimentIssues.Rproj", newSession = TRUE)

```

<BR><BR>
Plan B: If something fails, we always have the monkeys!

```{r, eval=FALSE}

browseURL("../jsPsychHelpeR-ExperimentIssues/outputs/reports/report_analysis_monkeys.html")

```

## {-}

![](img/perfect.png){fig-align="center"}

## Limitations

- Very easy to create new scales, and simple tasks, but complex experimental tasks <span style="color:orange;">require javascript and HTML knowledge</span> (although there are a good number of examples available)

- Data preparation for <span style="color:grey;">new experimental tasks</span> requires expertise in R (simple surveys not so much)  

- Analysis reports require some R knowledge (simple templates available)

- Requires access to a server for online tasks  

- Only behavioral tasks


# The future

## {background-color="black" background-image="img/future.jpg"}

## Too many things, too little time {background-image="img/working.gif"  background-size="20%" background-position="bottom right"}

- Create templates for most common experimental designs  
- Templates for data preparation and analysis of common experimental designs  
- More tasks, translations, tests, ...  
- So far, development based in our needs (and possibilities)  
- Upgrade to latest jsPsych when available  
- Improve, clean, share...  
- Publish jsPsychR paper  


## Help {background-image="img/help.png" background-size="20%" background-position="bottom right"}

- Javascript programmers

- R programmers

- Task creators

- Testers


## Back to Registered reports

<BR><BR><BR>
![](img/RR.webp)

## Can jsPsych really help? (1/2)

- With jsPsychR, protocols are standardized and with (mostly) clean code 

  + Less errors in protocols

- Data preparation is 90% automatic, standardized, and beautiful 

  + Less errors in data preparation

- When errors are found and fixed, **old** protocols can benefit from the corrections, old results can be checked, ...


## Can jsPsych really help? (2/2)

- Super easy to work on analysis <span style="color:darkgreen;">before</span> collecting human data

- Much easier to write up a good analysis plan, share it, improve it, ...

- Sharing protocol, materials, data preparation is trivial (single command)

- Creating future proof full reproducible projects (with Docker) is one command away



## RR + jsPsychR

![](img/reproducibility-crisis2_solved.jpeg){width=65% fig-align="center"}

## More information

For more information about RR, templates, checklists, list of participating journals (\>300), etc.:  

- [https://www.cos.io/initiatives/registered-reports](https://www.cos.io/initiatives/registered-reports)


Also, check out the future:  

- RR v2: [Peer community in](https://peercommunityin.org/)

And our manual:

- [https://gorkang.github.io/jsPsychRmanual/](https://gorkang.github.io/jsPsychRmanual/)

## References

::: {#refs}
:::

## Thanks!

<BR><BR>

Gorka Navarrete   

gorkang\@gmail.com  

https://fosstodon.org/\@gorkang  

